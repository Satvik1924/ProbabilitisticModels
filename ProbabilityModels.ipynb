{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nss4JzRcBWAf"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.8' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/msys64/mingw64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm, poisson\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3TcDcG6Be1-"
      },
      "source": [
        "Question-1 (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "DIFvsQgZBiCw",
        "outputId": "06fdd437-bb23-4b22-e547-2d2411811f4e"
      },
      "outputs": [],
      "source": [
        "# Define the probability of getting heads\n",
        "p = 0.2\n",
        "\n",
        "# Define the number of tosses\n",
        "n = 20\n",
        "\n",
        "# Toss the coin n times and store the outcomes\n",
        "outcomes = np.random.binomial(1, p, n)\n",
        "\n",
        "# Plot the outcomes against the trial number with dotted line\n",
        "plt.step(range(1, n+1), outcomes, color='violet', marker='o', linestyle='--', where='mid')\n",
        "\n",
        "# Add labels for heads and tails\n",
        "plt.yticks([0, 1], ['Tails(0)', 'Heads(1)'])\n",
        "\n",
        "# Modify the y-axis limit\n",
        "plt.ylim([-0.1, 1.1])\n",
        "\n",
        "plt.xlabel('Trial Number')\n",
        "plt.ylabel('Outcome')\n",
        "plt.title(f'Coin Tosses (n={n}, p={p})')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWKS52qwCXSV"
      },
      "source": [
        "The depicted plot illustrates a distribution wherein outcomes are uniformly spread across the spectrum from 0 to 1, akin to the expected results of a fair coin toss. Nonetheless, considering the probability of heads stands at a modest 0.2, a discernible imbalance, featuring fewer heads than tails over an extended duration, is anticipated. The manifestation of this expected discrepancy within this particular experimental setup hinges upon the outcome of the 20 coin tosses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiOxZ1mUC3fu"
      },
      "source": [
        "Question-1 (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-FNKhnLpC_vH",
        "outputId": "f7e55480-58ea-4892-c275-73b8478e2afb"
      },
      "outputs": [],
      "source": [
        "# Define the probability of getting heads\n",
        "p = 0.2\n",
        "\n",
        "# Define the number of tosses\n",
        "n = 20\n",
        "\n",
        "# Toss the coin n times and store the outcomes for 5 repeats\n",
        "outcomes = np.random.binomial(1, p, (5, n))\n",
        "\n",
        "# Custom colors for each line\n",
        "colors = ['skyblue', 'orange', 'green', 'red', 'yellow']\n",
        "\n",
        "# Plot the outcomes for each repeat against the trial number\n",
        "for i in range(5):\n",
        "    plt.step(range(1, n+1), outcomes[i], where='post', marker='o', color=colors[i], linestyle='--', linewidth=2, label=f\"Repeat {i+1}\")\n",
        "\n",
        "plt.xlabel(\"Trial Number\", fontsize=12)\n",
        "plt.ylabel(\"Outcome\", fontsize=12)\n",
        "plt.title(\"Outcomes of 5 repetitions of 20 Bernoulli trials with p=0.2\", fontsize=14)\n",
        "plt.legend(loc='upper right', fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.gca().set_facecolor('whitesmoke')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lJ1JLUlyZQc"
      },
      "source": [
        "\n",
        "Overall, the plot highlights the importance of repeating experiments to estimate the parameters of a probability distribution with confidence, as well as the inherent randomness and variability in the outcomes of random processes.\n",
        "The depicted plot exemplifies a distribution characterized by outcomes uniformly dispersed across the continuum ranging from 0 to 1, resembling the anticipated outcomes of a fair coin toss. However, given the probability of heads is a modest 0.2, an observable asymmetry is envisaged, whereby fewer instances of heads compared to tails are expected over a prolonged period. The realization of this envisaged disparity within the confines of this specific experimental framework is contingent upon the specific outcomes of the 20 coin tosses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZwSAOZREhnw"
      },
      "source": [
        "Question-1 (c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "bjcY5R0MEfF0",
        "outputId": "8f7fe8f5-5501-4f99-936c-35e400ef1ab7"
      },
      "outputs": [],
      "source": [
        "# Define the probability of getting heads\n",
        "p = 0.2\n",
        "\n",
        "# Define the number of tosses\n",
        "n = 20\n",
        "\n",
        "# Define the number of sequences\n",
        "m = 100\n",
        "\n",
        "# Toss the coin n times for m sequences and store the outcomes\n",
        "outcomes = np.random.binomial(1, p, (m, n))\n",
        "\n",
        "# Calculate the total number of heads for each sequence\n",
        "totals = outcomes.sum(axis=1)\n",
        "\n",
        "# Set the seaborn style\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Plot the histogram of total heads\n",
        "plt.hist(totals, bins=np.arange(n+1)-0.5, density=True, color='pink', edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Total Number of Heads')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.title(f'Distribution of Total Heads in {n}-Coin Tosses (m={m}, p={p})')\n",
        "\n",
        "# Add a vertical line indicating the expected value\n",
        "plt.axvline(x=p*n, color='red', linestyle='--', linewidth=2, label='Expected Value')\n",
        "\n",
        "# Add text annotation for the expected value\n",
        "plt.text(p*n + 0.5, 0.05, f'Expected Value: {p*n}', color='red', fontsize=10)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgEbxrGuypq9"
      },
      "source": [
        "Observation for part (c) :  \n",
        "    \n",
        "The resultant histogram should approximate a binomial distribution characterized by parameters \\( n = 20 \\) and \\( p = 0.2 \\). This distribution represents the probability mass function governing the number of successes in 20 independent Bernoulli trials, each with a probability of success of 0.2. Notably, we observe that the histogram's central tendency converges around 4, aligning with the theoretical expectation of \\( 20*0.2). Moreover, the histogram exhibits symmetry about this central value, consistent with the characteristic shape of the binomial distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtvCcHMJFtGp"
      },
      "source": [
        "Question-1 (d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "bRqF3RzyFvqG",
        "outputId": "50c668ea-91e7-4b6c-c904-d8126b276362"
      },
      "outputs": [],
      "source": [
        "# Define the probability of getting heads\n",
        "p = 0.2\n",
        "\n",
        "# Define the number of tosses\n",
        "n = 20\n",
        "\n",
        "# Define the number of sequences\n",
        "m = 100\n",
        "\n",
        "# Define the minimum sum of heads\n",
        "k = 3\n",
        "\n",
        "# Toss the coin n times for m sequences and store the outcomes\n",
        "outcomes = np.random.binomial(1, p, (m, n))\n",
        "\n",
        "# Calculate the total number of heads for each sequence\n",
        "totals = outcomes.sum(axis=1)\n",
        "\n",
        "# Choose only those sequences that sum to at least k\n",
        "selected = outcomes[totals >= k]\n",
        "selected_totals = selected.sum(axis=1)\n",
        "\n",
        "# Set seaborn style\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Plot the histogram of total heads for the selected sequences\n",
        "plt.hist(selected_totals, bins=np.arange(k, n+1)-0.5, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Total Number of Heads', fontsize=12)\n",
        "plt.ylabel('Probability Density', fontsize=12)\n",
        "plt.title(f'Distribution of Total Heads in {n}-Coin Tosses with at least {k} Heads (m={m}, p={p})', fontsize=14)\n",
        "\n",
        "# Customize the plot background and grid\n",
        "plt.gca().set_facecolor('whitesmoke')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add a vertical line indicating the minimum heads\n",
        "plt.axvline(x=k, color='red', linestyle='--', linewidth=2, label='Minimum Heads')\n",
        "\n",
        "# Add text annotation for the expected value\n",
        "plt.text(k + 0.5, 0.1, f'Minimum Heads: {k}', color='red', fontsize=10)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJaoWUclzBud"
      },
      "source": [
        "In part (d), we selectively include sequences where the cumulative sum equals or exceeds 3, subsequently plotting a histogram showcasing the total count of occurrences of '1's within these sequences. The underlying Probability Mass Function (PMF) approximated by this histogram aligns with the binomial distribution, characterized by parameters $n$ and $p$. Here, $n$ signifies the number of trials, set at 20, and $p$ denotes the probability of attaining a 'head' outcome, established at 0.2. Thus, the PMF that the histogram encapsulates corresponds to the binomial distribution with parameters $n=20$ and $p=0.2$.\n",
        "\n",
        "Looking at the plot, it's clear that each time we run the experiment, we get different results. This happens because of the randomness involved, like flipping a coin. But even though the outcomes vary, we can still see some consistent patterns. For example, in each round of the experiment, the number of successes tends to be around 20% of the total number of trials. This matches what we expect from a situation where each trial has a 20% chance of success.\n",
        "\n",
        "Also, as we do more trials, the results become more predictable. This matches up with something called the law of large numbers, which says that when you have a lot of data, the average of that data tends to get closer to what you expect.\n",
        "\n",
        "So, even though there's randomness involved, we can still see some regular patterns emerge as we keep doing the experiment more and more times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omhVkC0cGFSt"
      },
      "source": [
        "Question-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "BBi7qYr4GIc2",
        "outputId": "1878e0fa-60b0-4851-a072-056a6ea528e7"
      },
      "outputs": [],
      "source": [
        "# Step 1: Generate random values of alpha\n",
        "alphas = np.random.uniform(0, 100, 4)\n",
        "\n",
        "# Step 2: Choose n values for the Binomial distribution\n",
        "ns = np.ceil(10 * alphas).astype(int)\n",
        "\n",
        "# Step 3: Set the number of experiments\n",
        "num_experiments = 10000\n",
        "\n",
        "# Step 4: Simulate Binomial random variables\n",
        "binom_vars = []\n",
        "for i in range(4):\n",
        "    p = alphas[i] / ns[i]\n",
        "    binom_vals = np.random.binomial(ns[i], p, num_experiments)\n",
        "    binom_vars.append(binom_vals)\n",
        "\n",
        "# Step 5: Simulate Poisson random variables\n",
        "poisson_vars = []\n",
        "for alpha in alphas:\n",
        "    poisson_vals = np.random.poisson(alpha, num_experiments)\n",
        "    poisson_vars.append(poisson_vals)\n",
        "\n",
        "# Plotting histograms\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting Binomial histograms\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.hist(binom_vars[i], bins='auto', density=True, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    plt.title(f\"Binomial (n={ns[i]}, p={alphas[i]/ns[i]:.2f})\")\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Plotting Poisson histograms\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 4, i+5)\n",
        "    plt.hist(poisson_vars[i], bins='auto', density=True, color='salmon', edgecolor='black', alpha=0.7)\n",
        "    plt.title(f\"Poisson (lambda={alphas[i]:.2f})\")\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q85lmTiizcr4"
      },
      "source": [
        "This code iteratively generates four random values of alpha from the interval (0, 100) and subsequently determines an appropriate n value for each alpha to ensure that the Probability Mass Function (PMF) of the corresponding binomial distribution bears visual resemblance to that of the respective Poisson distribution. The number of experiments is fixed at 10000 for both binomial and Poisson random variables to ensure a robust approximation of their PMFs.\n",
        "\n",
        "For each alpha value, the code calculates the corresponding probability (p) for the binomial distribution using the formula p = alpha/n. It then generates num_experiments (set to 10000) random values from the binomial distribution, characterized by parameters n and p, and aggregates them in a list named binom_vars. Similarly, for each alpha value, it generates num_experiments random values from the Poisson distribution with parameter alpha, and compiles them in a separate list named poisson_vars.\n",
        "\n",
        "Subsequently, the code proceeds to visualize histograms for each binomial and Poisson distribution via the matplotlib.pyplot.hist() function. It arranges four subplots in sequence for the binomial distributions and four subplots subsequently for the Poisson distributions. Each subplot illustrates the histogram for a distinct distribution, accompanied by pertinent distribution parameters delineated in the title.\n",
        "\n",
        "The resultant plot demonstrates that the binomial distributions serve as suitable approximations for the Poisson distributions given the chosen n values. The histograms of the binomial distributions exhibit visual similarity to those of the Poisson distributions, aligning with theoretical expectations. Notably, the histograms of the Poisson distributions manifest a comparable shape, with a predominant concentration of values around the mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SdXkCipGlZ9"
      },
      "source": [
        "Question-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ah2nnRwBGoGk",
        "outputId": "6e095bbb-ff41-4c1e-f203-10317a426c51"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Define lambda values\n",
        "lam1 = np.random.uniform(2, 5)\n",
        "lam2 = np.random.uniform(2, 5)\n",
        "\n",
        "# Define sequence of number of RVs to add\n",
        "n = [2, 4, 8, 16]\n",
        "\n",
        "# Define function to simulate Poisson sum and plot histogram\n",
        "def simulate_poisson_sum(lam1, lam2, n, plot_title):\n",
        "    # Generate n Poisson random variables with lambda lam1 and lam2\n",
        "    samples = np.random.poisson(lam1, size=n) + np.random.poisson(lam2, size=n)\n",
        "    # Calculate sample mean\n",
        "    sample_mean = np.mean(samples)\n",
        "    # Calculate sample standard deviation\n",
        "    sample_std = np.std(samples, ddof=1)\n",
        "    # Calculate theoretical normal distribution parameters\n",
        "    mu = n * (lam1 + lam2)\n",
        "    sigma = np.sqrt(n * (lam1 + lam2))\n",
        "    # Plot histogram of samples\n",
        "    plt.hist(samples, bins=20, density=True, color='skyblue', edgecolor='black', alpha=0.7, label='Sample')\n",
        "    # Plot theoretical normal distribution\n",
        "    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n",
        "    plt.plot(x, norm.pdf(x, mu, sigma), color='red', linestyle='-', label='Normal')\n",
        "    # Plot mean and standard deviation\n",
        "    plt.axvline(mu, color='k', linestyle='--', label='Mean')\n",
        "    plt.axvline(mu + sigma, color='r', linestyle='--', label='Std Dev')\n",
        "    plt.axvline(mu - sigma, color='r', linestyle='--')\n",
        "    # Set plot parameters\n",
        "    plt.title(plot_title)\n",
        "    plt.xlabel('Sum of RVs')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with appropriate plot title\n",
        "for i in n:\n",
        "    plot_title = f'Sum of Poisson RVs with λ1={lam1:.2f}, λ2={lam2:.2f}, and n={i}'\n",
        "    simulate_poisson_sum(lam1, lam2, i, plot_title)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0dQj3c7zotk"
      },
      "source": [
        "The law of large numbers says that when you have a bunch of random things happening, like flipping a coin or rolling a dice, and you do it a lot of times, the average of all those outcomes will get closer and closer to what you expect. So, if you keep flipping a fair coin, eventually you'll see about half heads and half tails.\n",
        "\n",
        "Now, the central limit theorem says something similar but a bit different. It says that if you add up a bunch of random things, even if they're not the same kind of thing, like adding up a bunch of dice rolls or coin flips, the total will tend to look like a bell curve, kind of like the shape of a normal distribution.\n",
        "\n",
        "So, in the code we have here, it's simulating these ideas with two types of random variables: Bernoulli and Poisson. Bernoulli random variables are just things that can have two outcomes, like flipping a coin. Poisson random variables are for counting rare events, like the number of cars passing by in an hour.\n",
        "\n",
        "The code runs these simulations many times, adding up the outcomes each time. As it does this more and more, the results start to look like what we expect from the law of large numbers and the central limit theorem. The averages get closer to what we expect, and the overall shape starts to look like a bell curve."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
